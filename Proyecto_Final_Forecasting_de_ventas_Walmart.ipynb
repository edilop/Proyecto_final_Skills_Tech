{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edilop/Proyecto_final_Skills_Tech/blob/main/Proyecto_Final_Forecasting_de_ventas_Walmart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TglS76DkjIMG"
      },
      "source": [
        "#Skills Tech\n",
        "#Proyecto Integrador - Generación 6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Objetivo\n",
        "#### En este proyecto, el alumno aplicará las habilidades obtenidas en el curso para generar un modelo que pueda hacer predicciones de ventas."
      ],
      "metadata": {
        "id": "m1msQ8rZQDH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Escenario\n",
        "####Eres un científico de datos dentro de la consultoría “El oráculo”, tienes la asignación de trabajar en una empresa de retail para predecir sus ventas semanales a diferentes niveles muestrales, a nivel tienda."
      ],
      "metadata": {
        "id": "zAScajumQJTc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_yiyAT9xDof"
      },
      "source": [
        "##Sección 1. Obtención de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djg3m37bnArP"
      },
      "source": [
        "###1.1.Importamos las librerías"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Versión de python \n",
        "!python --version"
      ],
      "metadata": {
        "id": "_iwyvUHR7LN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpCmtuMSohDg"
      },
      "outputs": [],
      "source": [
        "#Manipulación de datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime #Manipulación de tiempo\n",
        "from time import process_time_ns #Medición de tiempo\n",
        "\n",
        "#Librerías estadísticas\n",
        "from statsmodels.tsa.stattools import pacf, acf #Autocorrelaciones\n",
        "from scipy import stats #Prueba de Kruskal-Wallis\n",
        "\n",
        "#Visualización de datos\n",
        "import plotly.express as px #Librería de gráficos\n",
        "import plotly.graph_objects as go #Librería plotly para objetos gráficos\n",
        "from plotly.subplots import make_subplots #Subgráficos dentro de un aréa\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf #Gráficos acf, pacf\n",
        "\n",
        "#Seteo de opciones\n",
        "pd.options.plotting.backend = \"plotly\" #Cambia motor de gráficas de pandas a plotly\n",
        "pd.options.display.float_format = '{:,.2f}'.format #Configuramos los valores float a 2 decimales\n",
        "\n",
        "#Machine Learning\n",
        "#Instalamos librerías\n",
        "!pip install pmdarima #Autoarima\n",
        "!pip install neuralprophet #Neural prophet\n",
        "\n",
        "#Importamos librerías de ML\n",
        "import pmdarima #Auto arima\n",
        "from sklearn.metrics import mean_squared_error #RMSE\n",
        "from prophet import Prophet #Facebook prophet\n",
        "from neuralprophet import NeuralProphet #Neural Prophet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvVJS5LQnH0v"
      },
      "source": [
        "###1.2.Carga del set de datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los datos\n",
        "url = 'https://raw.githubusercontent.com/edilop/Proyecto_final_Skills_Tech/36a03076872a497869ab40e93f934a596640a665/Walmart_Store_sales.csv'\n",
        "data = pd.read_csv(url, encoding='utf-8')\n",
        "#Creamos el dataframe de trabajo\n",
        "walmart_df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "uTvg8FB2m4dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnZktWpzowdT"
      },
      "source": [
        "##Sección 2. Análisis Exploratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7RGrQ5Sy6T2"
      },
      "source": [
        "###2.1.Descripción de los Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34H5bPs7VuoV"
      },
      "outputs": [],
      "source": [
        "#Muestra del dataframe.\n",
        "data.sample(n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV7OFsAzyA-6"
      },
      "outputs": [],
      "source": [
        "#Dimensiones del dataframe\n",
        "walmart_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Columnas del dataframe\n",
        "walmart_df.columns"
      ],
      "metadata": {
        "id": "7UgpWFqQCsoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agBXJ4ouozt0"
      },
      "outputs": [],
      "source": [
        "#Metadata\n",
        "walmart_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utj-3Bo2yTe6"
      },
      "outputs": [],
      "source": [
        "#Resumen\n",
        "walmart_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSf2vkY_o9qU"
      },
      "outputs": [],
      "source": [
        "#Conteo de datos nulos.\n",
        "walmart_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMdWaHKty2vC"
      },
      "source": [
        "###2.2.Análisis de relación entre variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe de variables agrupadas por ventas\n",
        "correlacion_df = walmart_df.groupby('Date').agg({'Weekly_Sales':'sum',\n",
        "                                            'Holiday_Flag':'mean',\n",
        "                                            'Temperature':'mean',\n",
        "                                            'Fuel_Price':'mean',\n",
        "                                            'CPI':'mean',\n",
        "                                            'Unemployment':'mean'})\\\n",
        "                                            .reset_index()\n",
        "#Calculamos la correlación\n",
        "cor = correlacion_df.corr()\n",
        "\n",
        "#Graficamos la correlación con un heatmap\n",
        "cor_heatm = go.Figure()\n",
        "cor_heatm.add_trace(go.Heatmap(z=cor,\n",
        "           x=cor.columns,\n",
        "           y=cor.columns,\n",
        "           zmin=-1,\n",
        "           zmax=1,\n",
        "           colorscale=px.colors.diverging.RdBu,\n",
        "           showscale=True,\n",
        "           text=cor,\n",
        "           texttemplate='%{text:.2f}',\n",
        "           )\n",
        ")\n",
        "cor_heatm.update_layout(template='ggplot2', yaxis_autorange='reversed', title='Heatmap de correlación entre variables')\n",
        "cor_heatm.show()"
      ],
      "metadata": {
        "id": "GrEGXN5HxbCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Historico de ventas de todas las sucursales                               \n",
        "#Arreglo con los días festivos\n",
        "fechas = ['2010-02-12', '2010-09-10', '2010-11-26', '2010-12-31',\n",
        "          '2011-02-11', '2011-09-09', '2011-11-25', '2011-12-30',\n",
        "          '2012-11-23', '2012-02-10',]\n",
        "#Dataframe\n",
        "linear = walmart_df.loc[:,['Date', 'Store', 'Weekly_Sales']]\n",
        "linear = linear.groupby(['Store', 'Date']).agg({'Weekly_Sales': 'sum'})\\\n",
        "                                          .reset_index()\n",
        "linear['Date'] = pd.to_datetime(linear.Date)\n",
        "linear = linear.sort_values(by='Date')\n",
        "#Graficamos el histograma de ventas de todas las sucursales\n",
        "fig = px.line(linear, x='Date', y='Weekly_Sales', color='Store', \n",
        "              title='Historico de ventas de las 45 sucursales', \n",
        "              template='seaborn',)\n",
        "#Trazamos los holidays como lineas negras verticales\n",
        "for i in range(len(fechas)):\n",
        "  fig.add_vline(x=fechas[i], line_width=3, line_dash=\"dash\", \n",
        "                line_color=\"black\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "0lmFmiXxO1E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Consolidado de ventas y boxplot.\n",
        "#Dataframe\n",
        "ventas_totales = walmart_df.groupby(['Date']).agg({'Weekly_Sales': 'sum'}) \\\n",
        "                .reset_index()\n",
        "ventas_totales['Date'] = pd.to_datetime(ventas_totales.Date)\n",
        "ventas_totales = ventas_totales.sort_values(by='Date')\n",
        "#Graficamos el histograma y el caja de bigotes de la evolución de la ventas.\n",
        "fig_totales = make_subplots(rows=1, cols=2,\n",
        "                      subplot_titles=('Histórico de Ventas', \n",
        "                                      'Boxplot de Ventas'))\n",
        "#Histogram\n",
        "fig_totales.add_trace(go.Scatter(x=ventas_totales.Date, \n",
        "                                 y=ventas_totales.Weekly_Sales), col=1, row=1)\n",
        "#Boxplot\n",
        "fig_totales.add_trace(go.Box(x=ventas_totales.Weekly_Sales, boxpoints='all', \n",
        "                             boxmean=True), col=2, row=1)\n",
        "\n",
        "#Config\n",
        "fig_totales.update_layout(showlegend=False, template='seaborn', \n",
        "                          title='Histórico y Boxplot de ventas consolidadas')\n",
        "fig_totales.show()"
      ],
      "metadata": {
        "id": "T1btzMUE_60H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG-DYp2GFt--"
      },
      "source": [
        "###2.3.Preguntas de Exploración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8W-fzPKF1wG"
      },
      "source": [
        "####2.3.1.¿Qué tienda tiene el máximo de ventas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTQ7xbOzGy9B"
      },
      "outputs": [],
      "source": [
        "#Obtenemos las 5 sucursales con más ventas\n",
        "question_231 = walmart_df.groupby(['Store']).agg(\n",
        "    {'Weekly_Sales': 'sum'}).sort_values(by='Weekly_Sales', \n",
        "                                        ascending=False).reset_index().head()\n",
        "question_231"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráfico de top 5 de tiendas con las mejores ventas\n",
        "question_231['Store'] = question_231['Store'].astype(str)\n",
        "fig_q231 = px.funnel(question_231, x='Weekly_Sales', \n",
        "                     y='Store',\n",
        "                     title='Top 5 tiendas con más ventas',\n",
        "                     template='seaborn',\n",
        "                     color='Weekly_Sales'\n",
        "                     )\n",
        "fig_q231.show()\n"
      ],
      "metadata": {
        "id": "Ln_On-auRLle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsIreH4CGCjI"
      },
      "source": [
        "####2.3.2.¿Qué tienda tiene la desviación estándar máxima, es decir, las ventas varían mucho. Además, averigüe el coeficiente de desviación medio?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AtjRVqCvaPF"
      },
      "outputs": [],
      "source": [
        "#Obtenemos las 5 sucursales con mayor desviación estándar\n",
        "question_232 = walmart_df.loc[:,['Store', 'Weekly_Sales']]\n",
        "question_232.columns = ['Store', 'Desv_std_max']\n",
        "question_232 = question_232.groupby(['Store']).std().sort_values(\n",
        "    by='Desv_std_max', ascending=False).reset_index()\n",
        "\n",
        "#Imprimimos el resultado\n",
        "print(f'La sucursal con mayor desviación estándar es: {question_232.iloc[0,0]} \\\n",
        "con un valor de: {question_232.Desv_std_max.max():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz5f1a1Y9DZs"
      },
      "outputs": [],
      "source": [
        "#Calculamos el coeficiente de desviación media\n",
        "#Seleccionamos la columna a analizar\n",
        "column = walmart_df[walmart_df.Store == 14].loc[:,'Weekly_Sales']\n",
        "\n",
        "#Calculamos la media y la desviación estándar\n",
        "mean = column.mean()\n",
        "std = column.std()\n",
        "\n",
        "#Calculamos el coeficiente de desviación media\n",
        "coef_desv_media = (std/mean)*100\n",
        "\n",
        "#Imprimimos el resultado\n",
        "print(f'El coeficiente de desviación media es de: {coef_desv_media:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graficamos el resultado\n",
        "fig_q232 = px.histogram(column,\n",
        "                        x='Weekly_Sales',\n",
        "                        y='Weekly_Sales',\n",
        "                        marginal='box',\n",
        "                        template='seaborn',\n",
        "                        title='Distribución de ventas Store 14'\n",
        "                        )\n",
        "fig_q232.show()"
      ],
      "metadata": {
        "id": "gAdCcm84RirN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoX6eLy-GD4h"
      },
      "source": [
        "####2.3.3.¿Qué tienda/s tiene una buena tasa de crecimiento trimestral en el tercer trimestre de 2012?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-zr_xTjsFUx"
      },
      "outputs": [],
      "source": [
        "#Creamos un nuevo dt para extraer la info necesaria.\n",
        "quarters_df = walmart_df.loc[:,['Store', 'Date', 'Weekly_Sales']]\n",
        "#Cambiamos el tipo de columna Date a tipo fecha.\n",
        "quarters_df['Date'] = pd.to_datetime(quarters_df[\"Date\"])\n",
        "#Creamos la columna 'Quarters' para identififcar los trimestres\n",
        "quarters_df['Quarters'] =  quarters_df['Date'].dt.quarter\n",
        "#Creamos la columna 'Years' para identificar los años.\n",
        "quarters_df['Years'] = quarters_df['Date'].dt.year\n",
        "#Seleccionamos solo los trimestres 2 y 3\n",
        "quarters_df = quarters_df[(quarters_df['Quarters'] == 2) | \n",
        "                          (quarters_df['Quarters'] == 3)]\n",
        "quarters_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9P6PMAvWH1a"
      },
      "outputs": [],
      "source": [
        "#Creamos el dataframe de trabajo para responder la pregunta 3.\n",
        "question3_df = pd.pivot_table(quarters_df,values='Weekly_Sales', \n",
        "                              index=['Store', 'Quarters'],\n",
        "                              columns='Years', aggfunc='sum',)\n",
        "question3_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_reQfvojqX5O"
      },
      "source": [
        "#####2.3.3.1. Análisis de crecimientos del 3er trimestre por cada año."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQkEXHIyZNg9"
      },
      "outputs": [],
      "source": [
        "#Creamos el dt.\n",
        "question3_df_1 = question3_df.copy().reset_index()\n",
        "#Añadimos las columnas de crecimineto por cada año de trimestres 2 y 3.\n",
        "# Función para calcular crecimiento entre 2do y 3er trimestre.\n",
        "def crecimiento(df, anio):\n",
        "  \"\"\"\n",
        "  Calcula las series \"Tasa de crecimiento\" del dataframe.\n",
        "  Calcula el crecimiento porcentual entre el 2do y 3er periodo de cada una de las sucur-\n",
        "  sales, y los añade a las Series de 'Tasa de crecimiento'.\n",
        "\n",
        "  Parametros:\n",
        "  df(pd.Series): Las ventas reflejadas en la serie seleccionada del dataframe.\n",
        "  anio: El año de la serie en la que ocurren las ventas de df.\n",
        "\n",
        "  Salida:\n",
        "  Devuelve una serie con los cálculos de los crecimientos, \n",
        "  \"\"\"\n",
        "  for i in range(len(df)):\n",
        "    if df.loc[i, 'Quarters'] == 3:\n",
        "      df.loc[i, f'Tasa de crecimiento {anio}'] = ((df.loc[i, anio]-df.loc[i-1, anio])/\n",
        "                                                  df.loc[i-1, anio])*100\n",
        "    else:\n",
        "      df.loc[i, f'Tasa de crecimiento {anio}'] = np.nan\n",
        "  pass\n",
        "\n",
        "#Aplicacion la función 'crecimiento' a los años 2010, 2011, 2012\n",
        "crecimiento(question3_df_1, 2010)\n",
        "crecimiento(question3_df_1, 2011)\n",
        "crecimiento(question3_df_1, 2012)\n",
        "\n",
        "#Reordenamos las columnas del dataframe\n",
        "question3_df_1 = question3_df_1.reindex(columns=['Store', 'Quarters', 2012, \n",
        "                                                 'Tasa de crecimiento 2012',\n",
        "                                                 2011, 'Tasa de crecimiento 2011', \n",
        "                                                 2010, 'Tasa de crecimiento 2010'])\n",
        "\n",
        "question3_df_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBpAq5zRAkE6"
      },
      "outputs": [],
      "source": [
        "#Grafico con plotly go\n",
        "fig3_1 = make_subplots(rows=3, cols=1,\n",
        "                      subplot_titles=('2012','2011','2010'))\n",
        "\n",
        "#2012\n",
        "fig3_1.add_trace(\n",
        "    go.Bar(x=question3_df_1['Store'], y=question3_df_1['Tasa de crecimiento 2012']),\n",
        "           row=1, col=1\n",
        ")\n",
        "\n",
        "#2011\n",
        "fig3_1.add_trace(\n",
        "    go.Bar(x=question3_df_1['Store'], y=question3_df_1['Tasa de crecimiento 2011']),\n",
        "           row=2, col=1\n",
        ")\n",
        "\n",
        "#2010\n",
        "fig3_1.add_trace(\n",
        "    go.Bar(x=question3_df_1['Store'], y=question3_df_1['Tasa de crecimiento 2010']),\n",
        "           row=3, col=1\n",
        ")\n",
        "\n",
        "fig3_1.update_layout(showlegend=False, template='seaborn', \n",
        "                     title_text='Tasa de crecimiento en % del 3er trimestre por año por sucursal')\n",
        "fig3_1.update_xaxes(tickvals=question3_df_1['Store'], zeroline=True)\n",
        "fig3_1.update_yaxes(zeroline=True, zerolinecolor='black')\n",
        "\n",
        "fig3_1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHpIUv8xyeuO"
      },
      "source": [
        "##### 2.3.3.2. Análisis de crecimiento del 3er trimestre entre cada año."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELeoI2iW4o1a"
      },
      "outputs": [],
      "source": [
        "#Creamos el dt.\n",
        "question3_df_2 = question3_df.reset_index()\n",
        "question3_df_2 = question3_df_2[question3_df_2['Quarters'] == 3]\n",
        "# question3_df_2 = question3_df.copy().reset_index()\n",
        "question3_df_2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xERblPKqaU84"
      },
      "outputs": [],
      "source": [
        "#Añadimos las columnas de crecimiento entre años.\n",
        "#Crecimiento entre año 2010 a 2011.\n",
        "question3_df_2['Tasa de crecimiento 2010-2011'] = ((question3_df_2[2011] - question3_df_2[2010])/question3_df_2[2010])*100\n",
        "#Crecimiento entre año 2011 a 2012.\n",
        "question3_df_2['Tasa de crecimiento 2011-2012'] = ((question3_df_2[2012] - question3_df_2[2011])/question3_df_2[2011])*100\n",
        "#Reordenamos las columnas del dataframe.\n",
        "question3_df_2 = question3_df_2.reindex(columns=['Store', \n",
        "                                                 'Quarters', \n",
        "                                                 2012, \n",
        "                                                 'Tasa de crecimiento 2011-2012', \n",
        "                                                 2011,\n",
        "                                                 'Tasa de crecimiento 2010-2011', \n",
        "                                                 2010,])\n",
        "question3_df_2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHZRXORNpaxf"
      },
      "outputs": [],
      "source": [
        "#Gráfico con plotly go\n",
        "fig3_2 = make_subplots(rows=2, cols=1,\n",
        "                      subplot_titles=('2011 - 2012','2010 - 2011'))\n",
        "#Tasa de crecimiento 2011-2012\n",
        "fig3_2.add_trace(\n",
        "    go.Bar(x=question3_df_2['Store'], y=question3_df_2['Tasa de crecimiento 2011-2012']),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "#Tasa de crecimiento 2010-2011\n",
        "fig3_2.add_trace(\n",
        "    go.Bar(x=question3_df_2['Store'], y=question3_df_2['Tasa de crecimiento 2010-2011']),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig3_2.update_layout(showlegend=False, template='seaborn', \n",
        "                     title_text='Tasa de crecimiento % del 3er trimestre entre años',\n",
        "                     xaxis_tickangle=-70\n",
        "                     )\n",
        "fig3_2.update_xaxes(tickvals=question3_df_2['Store'])\n",
        "fig3_2.update_yaxes(zeroline=True, zerolinecolor='black')\n",
        "\n",
        "fig3_2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FAw6Zl21hpw"
      },
      "outputs": [],
      "source": [
        "#Crecimiento por ventas.\n",
        "#Preparamos el dataframe\n",
        "question3_df_ventas = question3_df.copy().reset_index()\n",
        "question3_df_ventas = question3_df_ventas.loc[:,['Store', 'Quarters', 2012]]\n",
        "\n",
        "#Calculamos la columna de crecimiento\n",
        "for i in range(len(question3_df_ventas)):\n",
        "  if question3_df_ventas.loc[i, 'Quarters'] == 3:\n",
        "    question3_df_ventas.loc[i, 'Tasa de crecimiento 2012'] = (question3_df_ventas.loc[i, 2012] - question3_df_ventas.loc[i-1, 2012])\n",
        "  else:\n",
        "    question3_df_ventas.loc[i, 'Tasa de crecimiento 2012'] = np.nan\n",
        "\n",
        "question3_df_ventas.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = question3_df_ventas[question3_df_ventas['Quarters']==2].loc[:,['Store','Quarters',2012]]\n",
        "df_2 = question3_df_ventas[question3_df_ventas['Quarters']==3].loc[:,['Store','Quarters',2012]]"
      ],
      "metadata": {
        "id": "HR7DF-VvG7ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graficamos el crecimiento del año 2012\n",
        "fig3_3 = make_subplots(specs=[[{'secondary_y':True}]])\n",
        "fig3_3.add_trace(\n",
        "    go.Bar(x=df_1['Store'], y=df_1[2012], name='2do trim'),\n",
        "    secondary_y=False\n",
        ")\n",
        "#Ventas 2do trim\n",
        "fig3_3.add_trace(\n",
        "    go.Bar(x=df_1['Store'], y=df_2[2012], name = '3er trim'),\n",
        "    secondary_y = False\n",
        ")\n",
        "#Ventas 3er trim\n",
        "fig3_3.add_trace(\n",
        "    go.Scatter(x=df_1['Store'], \n",
        "               y=question3_df_ventas['Tasa de crecimiento 2012'].dropna(),\n",
        "               name = 'Crecimiento', mode = 'lines+markers', \n",
        "               line=dict(color = '#7d1a0c')),\n",
        "               secondary_y = True,\n",
        ")\n",
        "#Diferencia entre 2do y 3er trim\n",
        "fig3_3.update_layout(showlegend=True, template='seaborn', \n",
        "                     title_text='Tasa de crecimiento del 3er trimestre 2012',\n",
        "                     barmode='group')\n",
        "\n",
        "fig3_3.update_xaxes(tickvals=question3_df_ventas['Store'])\n",
        "fig3_3.update_yaxes(title_text = 'Ventas', secondary_y = False)\n",
        "fig3_3.update_yaxes(title_text = 'Crecimiento', secondary_y = True,\n",
        "                    zeroline = True, zerolinecolor ='#7d1a0c')\n",
        "\n",
        "fig3_3.show()"
      ],
      "metadata": {
        "id": "e962aot_CsB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94oGRiAo7MEu"
      },
      "outputs": [],
      "source": [
        "question3_df_ventas.loc[question3_df_ventas['Tasa de crecimiento 2012'] == question3_df_ventas['Tasa de crecimiento 2012'].max()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZOcc1hdB3S2"
      },
      "outputs": [],
      "source": [
        "question3_df_1.loc[question3_df_1['Tasa de crecimiento 2012'] == question3_df_1['Tasa de crecimiento 2012'].max()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDM5a4JhDQ1h"
      },
      "outputs": [],
      "source": [
        "question3_df_2.loc[question3_df_2['Tasa de crecimiento 2011-2012'] == question3_df_2['Tasa de crecimiento 2011-2012'].max()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT9myFKsGEEo"
      },
      "source": [
        "####2.3.4.¿Algunas festividades tienen un impacto negativo en las ventas. Averigüe los días festivos que tienen ventas más altas que las ventas medias en temporada no festiva para todas las tiendas juntas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkIghzc83Omo"
      },
      "outputs": [],
      "source": [
        "#Creamos el frame de trabajo\n",
        "question4_df = walmart_df.loc[:,['Store', 'Date','Weekly_Sales','Holiday_Flag']]\n",
        "#Cambiamos la columna 'Date' a tipo fecha.\n",
        "question4_df['Date'] = pd.to_datetime(question4_df['Date'], dayfirst=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15jsZCGNuSt-"
      },
      "outputs": [],
      "source": [
        "#Identificamos los días festivos.\n",
        "superbowl = ['2010-02-12', '2011-02-11','2012-02-10','2013-02-08']\n",
        "dia_trabajo = ['2010-09-10','2011-09-09','2012-09-07','2013-09-06']\n",
        "accion_gracias=['2010-11-26','2011-11-25','2012-11-23','2013-11-29']\n",
        "navidad = ['2010-12-31','2011-12-30','2012-12-28','2013-12-27']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyagaZkwuthZ"
      },
      "outputs": [],
      "source": [
        "#Añadimos los días festivos al dataframe.\n",
        "##Creamos la función que agregará los días festivos al dataframe.\n",
        "def isHoliday (x):\n",
        "  \"\"\"\n",
        "  Compara la fecha ingresada 'x' con varias listas, donde se encuentran almace-\n",
        "  nadas las fechas de 4 diferentes días festivos, si la fecha coincide, devolve-\n",
        "  rá el día festivo al que corresponda.\n",
        "\n",
        "  Parametros:\n",
        "  x(date): Fecha a buscar en las listas.\n",
        "\n",
        "  Salida:\n",
        "  Devuelve el nombre del día festivo según sea Superbolw, Día del trabajo, Acción\n",
        "  de gracias o Navidad.\n",
        "  \"\"\"\n",
        "  if x in superbowl:\n",
        "    return 'Superbowl'\n",
        "  elif x in dia_trabajo:\n",
        "    return 'Día de Trabajo'\n",
        "  elif x in accion_gracias:\n",
        "    return 'Acción de gracias'\n",
        "  elif x in navidad:\n",
        "    return 'Navidad'\n",
        "  else:\n",
        "    return 'None'\n",
        "##Agregamos la columna 'Festividad' al dataframe.\n",
        "question4_df['Festividad'] = question4_df['Date'].dt.strftime('%Y-%m-%d').apply(isHoliday)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVU_5VKAScG2"
      },
      "outputs": [],
      "source": [
        "#Comprobamos los valores de la columna 'Festividad'.\n",
        "question4_df['Festividad'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNqisUKngJ23"
      },
      "outputs": [],
      "source": [
        "#Creamos la columna 'Years'\n",
        "question4_df['Years'] = question4_df['Date'].dt.year\n",
        "question4_df['Years'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKTKEJd7bIlv"
      },
      "outputs": [],
      "source": [
        "#Agrupamos los datos para obtener los valores de las ventas agrupados por fecha.\n",
        "ventas_perdate = question4_df.groupby(['Date', 'Years', 'Festividad'],\n",
        "                                      as_index=False).agg({'Weekly_Sales': 'sum'})\n",
        "ventas_perdate.sort_values('Date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FShhYCY4nWvq"
      },
      "outputs": [],
      "source": [
        "#Filtramos los días festivos.\n",
        "holiday_df = ventas_perdate[ventas_perdate['Festividad'] != 'None']\n",
        "holiday_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_Qox2oVDVI7"
      },
      "outputs": [],
      "source": [
        "#Gráfico\n",
        "figura = go.Figure()\n",
        "figura.add_trace(go.Scatter(x=ventas_perdate['Date'], y=ventas_perdate['Weekly_Sales'],\n",
        "                         name='Ventas'))\n",
        "\n",
        "figura.add_trace(go.Scatter(x=holiday_df['Date'], y=holiday_df['Weekly_Sales'], text=holiday_df['Festividad'],\n",
        "                            mode='markers+text', name='Holidays', textposition='top center'))\n",
        "figura.update_layout(template='seaborn', title='Historico de ventas totales vs Holidays')\n",
        "figura.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZKNuuUIauQH"
      },
      "source": [
        "######2.3.4.1.Análisis de relación entre días festivos y evolución de ventas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5HP-KUOxjfK"
      },
      "outputs": [],
      "source": [
        "x = ventas_perdate['Weekly_Sales'][ventas_perdate['Festividad']!='None']\n",
        "y = ventas_perdate['Weekly_Sales'][ventas_perdate['Festividad']=='None']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U54_WI49yOub"
      },
      "outputs": [],
      "source": [
        "results = stats.kruskal(x,y)\n",
        "x, y = results\n",
        "print(f'p value = {y:.2f} > 0.05, por lo tanto, los holidays están relacionados con las ventas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwLA2vi9ve4e"
      },
      "source": [
        "##Sección 3. Modelado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBrjGUtspSEv"
      },
      "source": [
        "###3.1.Autoarima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jV4h-Mxr0IJ"
      },
      "outputs": [],
      "source": [
        "#Creamos el dataframe para trabajar con ARIMA.\n",
        "arima_df = ventas_perdate.loc[:,['Date', 'Weekly_Sales']]\n",
        "arima_df.set_index('Date', inplace=True)\n",
        "arima_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVGU2rAjHNsp"
      },
      "outputs": [],
      "source": [
        "#Graficamos la autocorrelación de la serie origin\n",
        "acf_fig = plot_acf(arima_df, lags=100)\n",
        "pacf_fig = plot_pacf(arima_df, method='ywm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXsOgJy1Oe25"
      },
      "outputs": [],
      "source": [
        "#Aplicamos la prueba a de Dickey-Fuller para probar estacionalidad.\n",
        "adf_test = pmdarima.arima.ADFTest(alpha=0.05)\n",
        "adf_test.should_diff(arima_df['Weekly_Sales'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7wOa9xk0uCF"
      },
      "outputs": [],
      "source": [
        "t1_start = process_time_ns() \n",
        "#Aplicamos el modelo autoarima\n",
        "stepwise_model=pmdarima.auto_arima(arima_df,\n",
        "                     start_p=1,\n",
        "                     start_q=1,\n",
        "                     test='adf',\n",
        "                     max_p=3,\n",
        "                     max_q=3,\n",
        "                     m=52,\n",
        "                      d=1,\n",
        "                      seasonal=True,\n",
        "                      start_P=0,\n",
        "                      D=1,\n",
        "                      trace=True,\n",
        "                      error_action='warn',\n",
        "                      suppress_warnings=True,\n",
        "                      stepwise=True,\n",
        "                      n_fits=10\n",
        "                     )\n",
        "\n",
        "t1_stop = process_time_ns()\n",
        "\n",
        "stepwise_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IINQ-47ykIR"
      },
      "outputs": [],
      "source": [
        "#Separar dataset en train y test.\n",
        "train_arima = arima_df.iloc[:-30]\n",
        "test_arima = arima_df.iloc[-30:]\n",
        "print(train_arima.shape, test_arima.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJWaNcVo96JS"
      },
      "outputs": [],
      "source": [
        "#Entrenamos el modelo\n",
        "stepwise_model.fit(train_arima)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ2lqzgJ60wN"
      },
      "outputs": [],
      "source": [
        "#Testeamos el modelo\n",
        "forecast_arima = stepwise_model.predict(n_periods=len(test_arima))\n",
        "forecast_arima = pd.DataFrame(forecast_arima, index=test_arima.index, columns=['Predicted_Weekly_Sales'])\n",
        "\n",
        "#Gráfico\n",
        "fig_arima = go.Figure([go.Scatter(x=test_arima.index, y=test_arima['Weekly_Sales'], name='Test Weekly Sales'),\n",
        "                    go.Scatter(x=forecast_arima.index,\n",
        "                               y=forecast_arima['Predicted_Weekly_Sales'], name='Predicted Weekly Sales')])\n",
        "fig_arima.update_layout(template='seaborn', title='Weekly Sales vs Predicted Weekly Sales with Auto arima')\n",
        "fig_arima.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos el error\n",
        "#Función para calcular el RMSE\n",
        "def rmse(actual, prediccion):\n",
        "  \"\"\"\n",
        "  Calcula el error cuadrático medio de un modelo de ML.\n",
        "\n",
        "  Parametros:\n",
        "  actual(np.array): Array de numpy con los valores reales\n",
        "  prediccion(np.array): Array de cumpy con los valores predichos por el modelo.\n",
        "\n",
        "  Salida:\n",
        "  float: El valor RMSE calculado del modelo\n",
        "  \"\"\"\n",
        "  RMSE = mean_squared_error(actual, prediccion, squared=False)\n",
        "  return RMSE\n",
        "\n",
        "#Función para calcular MAPE\n",
        "def mape(actual, prediccion):\n",
        "  \"\"\"\n",
        "  Calcula el error porcentual absoluto medio de un modelo de ML.\n",
        "\n",
        "  Parametros:\n",
        "  actual(np.array): Array de numpy con los valores reales\n",
        "  prediccion(np.array): Array de cumpy con los valores predichos por el modelo.\n",
        "\n",
        "  Salida:\n",
        "  float: El valor MAPE\n",
        "  \"\"\"\n",
        "  actual, prediccion = np.array(actual), np.array(prediccion)\n",
        "  MAPE = np.mean(np.abs(actual-prediccion)/actual) * 100\n",
        "  return MAPE"
      ],
      "metadata": {
        "id": "gcjfSfKUJ9hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x =  t1_stop-t1_start"
      ],
      "metadata": {
        "id": "wQXjr0PP52Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Guardamos los resultados en un dataframe\n",
        "error_df = pd.DataFrame(columns = ['Modelo', 'RMSE', 'MAPE'])\n",
        "error_df.loc[0,'Modelo'] = 'Autoarima'\n",
        "error_df.loc[0,'RMSE'] = rmse(test_arima.Weekly_Sales, forecast_arima.Predicted_Weekly_Sales)\n",
        "error_df.loc[0,'MAPE'] = mape(test_arima.Weekly_Sales, forecast_arima.Predicted_Weekly_Sales)\n",
        "error_df.loc[0, 'Speed (seg)'] = x/1000000000\n",
        "error_df"
      ],
      "metadata": {
        "id": "UlFCELciKdho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48rFM10JXfNx"
      },
      "source": [
        "###3.2.Prophet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos el dataframe.\n",
        "prophet_df = arima_df.copy().reset_index()\n",
        "#Cambiamos el nombre de las columnas por requerimiento del modelo\n",
        "prophet_df.columns=['ds','y']\n",
        "#Separamos los sets para entrenamiento y prueba.\n",
        "train_prophet = prophet_df.iloc[:-30]\n",
        "test_prophet = prophet_df.iloc[-30:]"
      ],
      "metadata": {
        "id": "FpsfEKz4Eb8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Iniciamos la función de toma de tiempo\n",
        "t2_start = process_time_ns()\n",
        "#Instanciamos el objeto prophet\n",
        "m = Prophet()\n",
        "#Entrenamos el modelo\n",
        "m.fit(train_prophet)\n",
        "#Hacemos el forecast con el modelo\n",
        "future = m.make_future_dataframe(periods=30, freq='W-FRI')\n",
        "forecast_prophet = m.predict(future)\n",
        "forecast_prophet.head()\n",
        "#Terminamos la función de toma de tiempo\n",
        "t2_stop = process_time_ns()\n",
        "x = t2_stop-t2_start"
      ],
      "metadata": {
        "id": "g2VRdl7ce0Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hacemos un plot del modelo\n",
        "m.plot(forecast_prophet);"
      ],
      "metadata": {
        "id": "F7DkB1-M1t6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot de los componentes del modelo\n",
        "m.plot_components(forecast_prophet);"
      ],
      "metadata": {
        "id": "wAmVfGZ7LVCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graficamos una comparación de los datos del test con los datos predichos por el\n",
        "#modelo\n",
        "fig_prophet = go.Figure([go.Scatter(x=test_prophet['ds'], y=test_prophet['y'], name='Test sales'),\n",
        "                    go.Scatter(x=forecast_prophet['ds'].iloc[-30:],\n",
        "                               y=forecast_prophet['yhat'].iloc[-30:], name='Predicted sales')])\n",
        "fig_prophet.update_layout(template='seaborn', title='Test Sales vs Predicted Sales with Prophet')\n",
        "fig_prophet.show()"
      ],
      "metadata": {
        "id": "Cp7pQdaMYYlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos el error\n",
        "#Guardamos los resultados en un dataframe\n",
        "error_df.loc[1,'Modelo'] = 'Prophet'\n",
        "error_df.loc[1,'RMSE'] = rmse(test_prophet.y, forecast_prophet.yhat.iloc[-30:])\n",
        "error_df.loc[1,'MAPE'] = mape(test_prophet.y, forecast_prophet.yhat.iloc[-30:])\n",
        "error_df.loc[1, 'Speed (seg)'] = x/1000000000\n",
        "error_df"
      ],
      "metadata": {
        "id": "HTrsqRybGuJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qslGuDUQYRRP"
      },
      "source": [
        "###3.3. Neural Prophet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos el dataframe.\n",
        "neuralp_df = prophet_df.copy()\n",
        "#Separamos los sets para entrenamiento y prueba.\n",
        "train_neuralp = neuralp_df.iloc[:-30]\n",
        "test_neuralp = neuralp_df.iloc[-30:]"
      ],
      "metadata": {
        "id": "NqC00KFiKETR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Iniciamos la función de toma de tiempo\n",
        "t3_start = process_time_ns()\n",
        "#Crear el objeto con el modelo.\n",
        "n = NeuralProphet(growth='linear')\n",
        "#Entrenamos el modelo.\n",
        "metrics = n.fit(train_neuralp, freq='W-FRI')\n",
        "#Hacemos el forecast con el modelo\n",
        "df_future = n.make_future_dataframe(train_neuralp, periods=29, n_historic_predictions=True)\n",
        "forecast_neuralp = n.predict(df_future)\n",
        "#Terminamos la función de toma de tiempo\n",
        "t3_stop = process_time_ns()\n",
        "x = t3_stop-t3_start"
      ],
      "metadata": {
        "id": "z4BNDOB-ihsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_neuralp.head()"
      ],
      "metadata": {
        "id": "Lj20-echkrR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hacemos un plot del modelo\n",
        "n.set_plotting_backend('plotly')\n",
        "fig = n.plot(forecast_neuralp);\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jrr2S04BPTcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hacemos plot de los componentes del modelo\n",
        "fig_components= n.plot_components(forecast_neuralp);\n",
        "fig_components.show()"
      ],
      "metadata": {
        "id": "l9arfAF0vrHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hacemos plot de los parametros del modelo\n",
        "fig_parameters = n.plot_parameters(forecast_neuralp);\n",
        "fig_parameters.show()"
      ],
      "metadata": {
        "id": "QiBRlj9aS-Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graficamos la comparación entre la predicción y los valores reales.\n",
        "fig_neuralp = go.Figure([go.Scatter(x=test_neuralp['ds'], y=test_neuralp['y'], name='Test sales'),\n",
        "                    go.Scatter(x=forecast_neuralp['ds'].iloc[-30:],\n",
        "                               y=forecast_neuralp['yhat1'].iloc[-30:], name='Predicted sales')])\n",
        "fig_neuralp.update_layout(template='seaborn', title='Test Sales vs Predicted Sales with Neural Prophet')\n",
        "fig_neuralp.show()"
      ],
      "metadata": {
        "id": "bO1vwnOMO-Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sección 4. Resultados"
      ],
      "metadata": {
        "id": "JOjNkmSDTUAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos el error\n",
        "#Guardamos los resultados en un dataframe\n",
        "error_df.loc[2,'Modelo'] = 'Neural Prophet'\n",
        "error_df.loc[2,'RMSE'] = rmse(test_neuralp.y, forecast_neuralp.yhat1.iloc[-30:])\n",
        "error_df.loc[2,'MAPE'] = mape(test_neuralp.y, forecast_neuralp.yhat1.iloc[-30:])\n",
        "error_df.loc[2, 'Speed (seg)'] = x/1000000000\n",
        "error_df"
      ],
      "metadata": {
        "id": "mEogkJlqTcSO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "mount_file_id": "1tC4kyOEMRai2X5dMi-eP1YoknOObRu9s",
      "authorship_tag": "ABX9TyNpHauwYQr8Y9UdgkKuruAw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}